{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19885b-55cf-4220-bf5d-21d4eb243a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion between 2 llms about joke\n",
    "\n",
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "\n",
    "import base64\n",
    "# from openai import AzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610be57c-f8fc-48f6-8790-4514bb3630d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "\n",
    "# personalise env data FOR AZURE OPENAI\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_URL\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "azure_openai_subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# personalise env data FOR DEEPSEEK AZURE OPENAI\n",
    "azure_deepseek_endpoint = os.getenv(\"DEEPSEEK_AZURE_INFERENCE_SDK_ENDPOINT\")\n",
    "azure_deepseek_deployment= os.getenv(\"DEPLOYMENT_NAME\", \"DeepSeek-V3-0324\")\n",
    "azure_deepseek_subscription_key = os.getenv(\"DEEPSEEK_AZURE_INFERENCE_SDK_KEY\")\n",
    "\n",
    "# personalise env data FOR GROK AZURE OPENAI\n",
    "azure_grok_endpoint = os.getenv(\"GROK_AZURE_INFERENCE_SDK_ENDPOINT\")\n",
    "azure_grok_deployment = os.getenv(\"GROK_DEPLOYMENT_NAME\", \"grok-3-mini\")\n",
    "azure_grok_subscription_key = os.getenv(\"GROK_AZURE_INFERENCE_SDK_KEY\")\n",
    "\n",
    "\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OPENAI API Key not set\")\n",
    "if azure_openai_subscription_key:\n",
    "    print(f\"AZURE OpenAI API Key exists and begins {azure_openai_subscription_key[:8]}\")\n",
    "else:\n",
    "    print(\"AZURE OPENAI API Key not set\")\n",
    "    \n",
    "# if anthropic_api_key:\n",
    "#     print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "# else:\n",
    "#     print(\"Anthropic API Key not set\")\n",
    "\n",
    "# if google_api_key:\n",
    "#     print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "# else:\n",
    "#     print(\"Google API Key not set\")\n",
    "if azure_deepseek_subscription_key:\n",
    "    print(f\"DEEPSEEK AZURE API Key exists and begins {azure_deepseek_subscription_key[:7]}\")\n",
    "else:\n",
    "    print(\"DEEPSEEK AZURE API Key not set\")\n",
    "\n",
    "if azure_grok_subscription_key:\n",
    "    print(f\"GROK_AZURE API Key exists and begins {azure_grok_subscription_key[:8]}\")\n",
    "else:\n",
    "    print(\"GROK_AZURE API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974f070b-9d5c-4d2d-91be-7ab942b3757c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ed683-4a60-400b-ad41-976dd44fcbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes \\\n",
    "a short summary, ignoring text that might be navigation related. \\\n",
    "try as much as possible not to exceed 1000 words. \\\n",
    "Respond in markdown.\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867f6638-6b48-4ad9-83cb-d81d61bee12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfb5675-4f84-4831-b407-5b0f9989fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT AZURE OPENAIS\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "clientGPTAzure = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_subscription_key,\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d3d207-14fa-4aa1-9d63-f315329865be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Include speech result if speech is enabled\n",
    "messages = prompts\n",
    "\n",
    "# Generate the completion\n",
    "completion = clientGPTAzure.chat.completions.create(\n",
    "    model=azure_openai_deployment,\n",
    "    messages=messages,\n",
    "    max_tokens=6553,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "# print(completionto_json())\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56645710-95e2-44ab-92a7-279207615729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEPSEEK AZURE OPENAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "clientDeepSeekAzure = ChatCompletionsClient(endpoint=azure_deepseek_endpoint, credential=AzureKeyCredential(azure_deepseek_subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795e8909-8d8e-44ee-bc8d-19847c8868f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysContent=\"You are an assistant that is great at telling jokes \\\n",
    "a short summary, ignoring text that might be navigation related. \\\n",
    "try as much as possible not to exceed 1000 words. \\\n",
    "Respond in markdown.\"\n",
    "usrContent=\"Tell a light-hearted joke for an audience of Data Scientists, response should be in markdown format\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba9def-acbf-4aef-bf2d-9992136ad661",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = clientDeepSeekAzure.complete(\n",
    "  messages=[\n",
    "    SystemMessage(content=sysContent),\n",
    "    UserMessage(content=usrContent)\n",
    "  ],\n",
    "  model = azure_deepseek_deployment,\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04126580-0b11-4d9c-987b-118af2ba43ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROK AZURE OPENAI\n",
    "\n",
    "clientGrokAzure = ChatCompletionsClient(endpoint=azure_grok_endpoint, credential=AzureKeyCredential(azure_grok_subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b92b68-4794-42ec-90f6-cd37a76adc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = clientGrokAzure.complete(\n",
    "  messages=[\n",
    "    SystemMessage(content=sysContent),\n",
    "    UserMessage(content=usrContent)\n",
    "  ],\n",
    "  model = azure_grok_deployment,\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae192ac-437c-4107-a766-5970f098700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3868bb-05dd-4c3f-b375-4f78b564d8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4.1-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6687e63-4820-4007-af8c-4b692afa2328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4.1-mini and Claude-3.5-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "\n",
    "azure_openai_gpt_model = \"gpt-4o-mini\"\n",
    "azure_deepseek_model = azure_deepseek_deployment\n",
    "\n",
    "azure_openai_gpt_system = \"You are a chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way.\"\n",
    "\n",
    "azure_deepseek_system = \"You are a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting.\"\n",
    "\n",
    "\n",
    "azure_openai_gpt_messages = [\"Hi there\"]\n",
    "azure_deepseek_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79e1945-d696-4777-941c-b6da52c3623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    # print(f\"inside call_gpt,Before zip function \\n azure_openai_gpt_messages: \\n {azure_openai_gpt_messages} \\n azure_deepseek_messages \\n{azure_deepseek_messages} \")\n",
    "    messages = [{\"role\": \"system\", \"content\": azure_openai_gpt_system}]\n",
    "    for gpt, deepseek in zip(azure_openai_gpt_messages, azure_deepseek_messages):\n",
    "        # print(f\"picking each value from gpt, deepseek \\n gpt i/p message: \\n {gpt} \\n deepseek i/p message \\n{deepseek} \")\n",
    "    \n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": deepseek})\n",
    "    # completion = openai.chat.completions.create(\n",
    "    #     model=gpt_model,\n",
    "    #     messages=messages\n",
    "    # )\n",
    "    # return completion.choices[0].message.content\n",
    "\n",
    "    # Include speech result if speech is enabled\n",
    "    # messages = prompts\n",
    "\n",
    "    # Generate the completion\n",
    "    completion = clientGPTAzure.chat.completions.create(\n",
    "    model=azure_openai_deployment,\n",
    "    messages=messages,\n",
    "    max_tokens=6553,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False\n",
    "    )\n",
    "\n",
    "    # print(completionto_json())\n",
    "    return (completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f5fa0-8575-47b2-8e8b-387d4732f500",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0e66e-4cdb-4bad-9d4a-f822666bd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_azure_deepseek():\n",
    "    # print(f\"inside call_azure_deepseek,Before zip function \\n azure_openai_gpt_messages: \\n {azure_openai_gpt_messages} \\n azure_deepseek_messages \\n{azure_deepseek_messages} \")\n",
    "    \n",
    "    messages = []\n",
    "    for gpt, azure_deepseek_message in zip(azure_openai_gpt_messages, azure_deepseek_messages):\n",
    "        # print(f\"picking each value from gpt, azure_deepseek_message \\n gpt i/p message: \\n {gpt} \\n azure_deepseek_message i/p message \\n{azure_deepseek_message} \")\n",
    "    \n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": azure_deepseek_message})\n",
    "        messages.append({\"role\": \"user\", \"content\": azure_openai_gpt_messages[-1]})\n",
    "    # message = claude.messages.create(\n",
    "    #     model=claude_model,\n",
    "    #     system=claude_system,\n",
    "    #     messages=messages,\n",
    "    #     max_tokens=500\n",
    "    # )\n",
    "    message = clientDeepSeekAzure.complete(\n",
    "        messages=messages,\n",
    "      model=azure_deepseek_deployment,\n",
    "      max_tokens=1000\n",
    "    )\n",
    "\n",
    "    # print(response)\n",
    "    # print(response.choices[0].message.content)\n",
    "    return message.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eedaa4-6f0c-40ec-8572-cfb9c0eb7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    " call_azure_deepseek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b073b95e-a40b-4ac4-8af5-cb6d0d48e06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ad5e6a-a5a0-4c84-9ecc-bc629647b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "azure_openai_gpt_messages = [\"Hi there\"]\n",
    "azure_deepseek_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"Azure OpenAI GPT:\\n{azure_openai_gpt_messages[0]}\\n\")\n",
    "print(f\"Azure Deepseek:\\n{azure_deepseek_messages[0]}\\n\")\n",
    "\n",
    "for i in range(2):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"Azure OpenAI GPT:\\n{gpt_next}\\n\")\n",
    "    azure_openai_gpt_messages.append(gpt_next)\n",
    "    \n",
    "    azure_deepseek_next = call_azure_deepseek()\n",
    "    print(f\"Azure Deepseek:\\n{azure_deepseek_next}\\n\")\n",
    "    azure_deepseek_messages.append(azure_deepseek_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa3fd0-04bd-4359-99a0-304261f5b1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

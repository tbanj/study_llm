{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7375ccf0-fe58-46a1-b932-ec5ae494654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion between 3 llms about joke\n",
    "\n",
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, AzureOpenAI, AsyncOpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display\n",
    "\n",
    "\n",
    "import base64\n",
    "# from openai import AzureOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e8479c-607e-405e-ae3f-f5914a575f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "\n",
    "# personalise env data FOR AZURE OPENAI\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT_URL\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\", \"gpt-4o-mini\")\n",
    "azure_openai_subscription_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "# personalise env data FOR DEEPSEEK AZURE OPENAI\n",
    "azure_deepseek_endpoint = os.getenv(\"DEEPSEEK_AZURE_INFERENCE_SDK_ENDPOINT\")\n",
    "azure_deepseek_deployment= os.getenv(\"DEPLOYMENT_NAME\", \"DeepSeek-V3-0324\")\n",
    "azure_deepseek_subscription_key = os.getenv(\"DEEPSEEK_AZURE_INFERENCE_SDK_KEY\")\n",
    "\n",
    "# personalise env data FOR GROK AZURE OPENAI\n",
    "azure_grok_endpoint = os.getenv(\"GROK_AZURE_INFERENCE_SDK_ENDPOINT\")\n",
    "azure_grok_deployment = os.getenv(\"GROK_DEPLOYMENT_NAME\", \"grok-3-mini\")\n",
    "azure_grok_subscription_key = os.getenv(\"GROK_AZURE_INFERENCE_SDK_KEY\")\n",
    "\n",
    "\n",
    "# anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OPENAI API Key not set\")\n",
    "if azure_openai_subscription_key:\n",
    "    print(f\"AZURE OpenAI API Key exists and begins {azure_openai_subscription_key[:8]}\")\n",
    "else:\n",
    "    print(\"AZURE OPENAI API Key not set\")\n",
    "    \n",
    "# if anthropic_api_key:\n",
    "#     print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "# else:\n",
    "#     print(\"Anthropic API Key not set\")\n",
    "\n",
    "# if google_api_key:\n",
    "#     print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "# else:\n",
    "#     print(\"Google API Key not set\")\n",
    "if azure_deepseek_subscription_key:\n",
    "    print(f\"DEEPSEEK AZURE API Key exists and begins {azure_deepseek_subscription_key[:7]}\")\n",
    "else:\n",
    "    print(\"DEEPSEEK AZURE API Key not set\")\n",
    "\n",
    "if azure_grok_subscription_key:\n",
    "    print(f\"GROK_AZURE API Key exists and begins {azure_grok_subscription_key[:8]}\")\n",
    "else:\n",
    "    print(\"GROK_AZURE API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40721e-c10e-4dc8-9caa-c7b81302427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00b3761-301a-4c5b-b76a-0e660c20ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes \\\n",
    "a short summary, ignoring text that might be navigation related. \\\n",
    "try as much as possible not to exceed 1000 words. \\\n",
    "Respond in markdown.\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45899a8c-30fb-40ca-9c63-c896f3167ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6e2620-b068-4fcd-bf7b-a330d56e777c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT AZURE OPENAIS\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "clientGPTAzure = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_subscription_key,\n",
    "    api_version=\"2025-01-01-preview\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c0635c-1b4e-4e48-80b5-36be2ea20927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Include speech result if speech is enabled\n",
    "messages = prompts\n",
    "\n",
    "# Generate the completion\n",
    "completion = clientGPTAzure.chat.completions.create(\n",
    "    model=azure_openai_deployment,\n",
    "    messages=messages,\n",
    "    max_tokens=6553,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False\n",
    ")\n",
    "\n",
    "# print(completionto_json())\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad45f85-f845-4e82-9ee5-879a9d582b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEPSEEK AZURE OPENAI\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "clientDeepSeekAzure = ChatCompletionsClient(endpoint=azure_deepseek_endpoint, credential=AzureKeyCredential(azure_deepseek_subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26990a7d-01d4-4021-8785-445761598c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sysContent=\"You are an assistant that is great at telling jokes \\\n",
    "a short summary, ignoring text that might be navigation related. \\\n",
    "try as much as possible not to exceed 1000 words. \\\n",
    "Respond in markdown.\"\n",
    "usrContent=\"Tell a light-hearted joke for an audience of Data Scientists, response should be in markdown format\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacd455d-d225-4ab1-98ad-20f24df98f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = clientDeepSeekAzure.complete(\n",
    "  messages=[\n",
    "    SystemMessage(content=sysContent),\n",
    "    UserMessage(content=usrContent)\n",
    "  ],\n",
    "  model = azure_deepseek_deployment,\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e260661-db32-46bf-85a0-4a77b7bea98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROK AZURE OPENAI\n",
    "\n",
    "clientGrokAzure = ChatCompletionsClient(endpoint=azure_grok_endpoint, credential=AzureKeyCredential(azure_grok_subscription_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005a7f1-a90b-4354-8ff8-2675b3ce8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = clientGrokAzure.complete(\n",
    "  messages=[\n",
    "    SystemMessage(content=sysContent),\n",
    "    UserMessage(content=usrContent)\n",
    "  ],\n",
    "  model=azure_grok_deployment,\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "# print(response)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88aaf52a-7a9d-4449-9ffe-5645af58b408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "azure_openai_gpt_model = \"gpt-4o-mini\"\n",
    "azure_deepseek_model = azure_deepseek_deployment\n",
    "\n",
    "azure_openai_gpt_system = \"You are Charlie, chatbot who is very argumentative; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a snarky way. \\\n",
    "Introduce yourself as Charlie to start the conversation, your colleagues are Blake and Alex\"\n",
    "\n",
    "azure_deepseek_system = \"You are Blake, a very polite, courteous chatbot. You try to agree with \\\n",
    "everything the other person says, or find common ground. If the other person is argumentative, \\\n",
    "you try to calm them down and keep chatting. Introduce yourself as Blake to start the conversation, \\\n",
    "your colleagues are Charlie and Alex\"\n",
    "\n",
    "azure_grok_system = \"You are Alex, a very polite, courteous chatbot. You try to think differently \\\n",
    "about what they have said so far, introducing fresh ideas or suggestion to the conversation \\\n",
    "or find common ground. If both Blake and Charlie are arguing or in agreement, you are free to choose \\\n",
    "who you want to support is idea at random. Always say something\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "azure_openai_gpt_messages = [\"Hi there\"]\n",
    "azure_deepseek_messages = [\"Hi\"]\n",
    "\n",
    "conversation = \", \".join(azure_openai_gpt_messages + azure_deepseek_messages)\n",
    "\n",
    "print(conversation)\n",
    "azure_grok = f\"\"\"\n",
    "    You are Alex, in conversation with Blake and Charlie.\n",
    "    The conversation so far is as follows:\n",
    "    {conversation}\n",
    "    Now with this, respond with what you would like to say next, as Alex.\n",
    "    \"\"\"\n",
    "azure_grok_messages  = [azure_grok]\n",
    "print(azure_grok_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00be62-c6fb-4a4b-b8c7-e69f5e5f839b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "def call_gpt():\n",
    "    # print(f\"inside call_gpt,Before zip function \\n azure_openai_gpt_messages: \\n {azure_openai_gpt_messages} \\n azure_deepseek_messages \\n{azure_deepseek_messages} \")\n",
    "    messages = [{\"role\": \"system\", \"content\": azure_openai_gpt_system}]\n",
    "    for gpt, deepseek in zip(azure_openai_gpt_messages, azure_deepseek_messages):\n",
    "        # print(f\"picking each value from gpt, deepseek \\n gpt i/p message: \\n {gpt} \\n deepseek i/p message \\n{deepseek} \")\n",
    "    \n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": deepseek})\n",
    "   \n",
    "    # Generate the completion\n",
    "    completion = clientGPTAzure.chat.completions.create(\n",
    "    model=azure_openai_deployment,\n",
    "    messages=messages,\n",
    "    max_tokens=6553,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=None,\n",
    "    stream=False\n",
    "    )\n",
    "\n",
    "    # print(completionto_json())\n",
    "    return (completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2346146-233f-49f4-9c08-43b8289c9a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def call_azure_deepseek():\n",
    "    # print(f\"inside call_azure_deepseek,Before zip function \\n azure_openai_gpt_messages: \\n {azure_openai_gpt_messages} \\n azure_deepseek_messages \\n{azure_deepseek_messages} \")\n",
    "    \n",
    "    messages = []\n",
    "    for gpt, azure_deepseek_message in zip(azure_openai_gpt_messages, azure_deepseek_messages):\n",
    "        # print(f\"picking each value from gpt, azure_deepseek_message \\n gpt i/p message: \\n {gpt} \\n azure_deepseek_message i/p message \\n{azure_deepseek_message} \")\n",
    "    \n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": azure_deepseek_message})\n",
    "        messages.append({\"role\": \"user\", \"content\": azure_openai_gpt_messages[-1]})\n",
    "    # message = claude.messages.create(\n",
    "    #     model=claude_model,\n",
    "    #     system=claude_system,\n",
    "    #     messages=messages,\n",
    "    #     max_tokens=500\n",
    "    # )\n",
    "    message = clientDeepSeekAzure.complete(\n",
    "        messages=messages,\n",
    "      model=azure_deepseek_deployment,\n",
    "      max_tokens=1000\n",
    "    )\n",
    "\n",
    "    # print(response)\n",
    "    # print(response.choices[0].message.content)\n",
    "    return message.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb6715e-42a8-4559-b404-50b696199cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "def call_azure_grok():\n",
    "    # print(f\"inside call_azure_deepseek,Before zip function \\n azure_openai_gpt_messages: \\n {azure_openai_gpt_messages} \\n azure_deepseek_messages \\n{azure_deepseek_messages} \")\n",
    "    \n",
    "    messages = []\n",
    "    for deepseek, azure_grok_message in zip(azure_deepseek_messages, azure_grok_messages):\n",
    "        # print(f\"picking each value from gpt, azure_deepseek_message \\n gpt i/p message: \\n {gpt} \\n azure_deepseek_message i/p message \\n{azure_deepseek_message} \")\n",
    "    \n",
    "        messages.append({\"role\": \"user\", \"content\": deepseek})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": azure_grok_message})\n",
    "        messages.append({\"role\": \"user\", \"content\": azure_deepseek_messages[-1]})\n",
    "   \n",
    "    message =  clientGrokAzure.complete(\n",
    "        messages=messages,\n",
    "      model=azure_grok_deployment,\n",
    "      max_tokens=1000\n",
    "    )\n",
    "\n",
    "    # print(response)\n",
    "    # print(response.choices[0].message.content)\n",
    "    return message.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62828494-c04c-4210-b7e4-2043b1389052",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b4c19c-e1ff-48ef-a063-fe4890f26772",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_azure_deepseek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d3616-7458-4720-bf5d-bb4ab4d2bbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_azure_grok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aedae46-48bd-4b98-bbaf-5b9000df610d",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_openai_gpt_messages = [\"Hi there\"]\n",
    "azure_deepseek_messages = [\"Hi\"]\n",
    "\n",
    "conversation = \", \".join(azure_openai_gpt_messages + azure_deepseek_messages)\n",
    "\n",
    "# print(conversation)\n",
    "azure_grok = f\"\"\"\n",
    "    You are Alex, in conversation with Blake and Charlie.\n",
    "    The conversation so far is as follows:\n",
    "    {conversation}\n",
    "    Now with this, respond with what you would like to say next, as Alex.\n",
    "    \"\"\"\n",
    "azure_grok_messages  = [azure_grok]\n",
    "\n",
    "print(f\"Azure OpenAI GPT:\\n{azure_openai_gpt_messages[0]}\\n\")\n",
    "print(f\"Azure Deepseek:\\n{azure_deepseek_messages[0]}\\n\")\n",
    "print(f\"Azure Grok:\\n{azure_grok_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"Azure OpenAI GPT:\\n{gpt_next}\\n\")\n",
    "    azure_openai_gpt_messages.append(gpt_next)\n",
    "    \n",
    "    azure_deepseek_next = call_azure_deepseek()\n",
    "    print(f\"Azure Deepseek:\\n{azure_deepseek_next}\\n\")\n",
    "    azure_deepseek_messages.append(azure_deepseek_next)\n",
    "\n",
    "    azure_grok_next = call_azure_grok()\n",
    "    if(azure_grok_next):\n",
    "        print(f\"Azure Grok:\\n{azure_grok_next}\\n\")\n",
    "        azure_grok_messages.append(azure_grok_next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082db29-6bcd-4de4-ba2b-430486418316",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
